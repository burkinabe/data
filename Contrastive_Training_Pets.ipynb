{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sayakpaul/Supervised-Constrastive-Learning-in-TensorFlow-2/blob/master/Contrastive_Training_Pets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0j-TQLq1_84S"
   },
   "source": [
    "## References:\n",
    "- https://arxiv.org/pdf/2004.11362.pdf\n",
    "- https://towardsdatascience.com/contrastive-loss-for-supervised-classification-224ae35692e7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Bk9fkKLBmTO"
   },
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lIYdn1woOS1n",
    "outputId": "7b06e6b4-3ce0-483f-9dec-8e8001b027a4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-23 05:50:12.495848: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-23 05:50:13.562495: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "PsvLs8bn2k7j",
    "outputId": "7c26cd17-9e0c-4938-a527-b35eb0d4eaa8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 23 05:50:24 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   50C    P8     6W /  80W |    409MiB /  6144MiB |      5%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2101      G   /usr/lib/xorg/Xorg                209MiB |\n",
      "|    0   N/A  N/A     56593      G   /usr/bin/gnome-shell               98MiB |\n",
      "|    0   N/A  N/A     57550      G   ...496834164065214108,262144       97MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (0.15.4)\n",
      "Requirement already satisfied: tensorflow_datasets in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (4.9.2)\n",
      "Requirement already satisfied: tensorflow_addons in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (0.20.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: setproctitle in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from wandb) (8.0.4)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from wandb) (3.1.31)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: setuptools in /home/aksavadogo/.local/lib/python3.10/site-packages (from wandb) (67.8.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from wandb) (4.23.2)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from wandb) (1.26.0)\n",
      "Requirement already satisfied: PyYAML in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/aksavadogo/.local/lib/python3.10/site-packages (from wandb) (2.28.2)\n",
      "Requirement already satisfied: pathtools in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: absl-py in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from tensorflow_datasets) (1.4.0)\n",
      "Requirement already satisfied: wrapt in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from tensorflow_datasets) (1.14.1)\n",
      "Requirement already satisfied: numpy in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from tensorflow_datasets) (1.24.3)\n",
      "Requirement already satisfied: tqdm in /home/aksavadogo/.local/lib/python3.10/site-packages (from tensorflow_datasets) (4.65.0)\n",
      "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from tensorflow_datasets) (1.3.0)\n",
      "Requirement already satisfied: dm-tree in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from tensorflow_datasets) (0.1.8)\n",
      "Requirement already satisfied: toml in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from tensorflow_datasets) (0.10.2)\n",
      "Requirement already satisfied: termcolor in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from tensorflow_datasets) (2.3.0)\n",
      "Requirement already satisfied: array-record in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from tensorflow_datasets) (0.4.0)\n",
      "Requirement already satisfied: promise in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: tensorflow-metadata in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from tensorflow_datasets) (1.13.1)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from tensorflow_addons) (2.13.3)\n",
      "Requirement already satisfied: packaging in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from tensorflow_addons) (23.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: typing_extensions in /home/aksavadogo/.local/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (4.6.3)\n",
      "Requirement already satisfied: importlib_resources in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (5.12.0)\n",
      "Requirement already satisfied: zipp in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (3.11.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/aksavadogo/.local/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from tensorflow-metadata->tensorflow_datasets) (1.59.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/aksavadogo/anaconda3/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb tensorflow_datasets tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3_eMx9da2wrn",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mQm3mkRV4Kdb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-06-23 00:43:57--  https://raw.githubusercontent.com/wangz10/contrastive_loss/master/losses.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5169 (5.0K) [text/plain]\n",
      "Saving to: ‘losses.py.3’\n",
      "\n",
      "losses.py.3         100%[===================>]   5.05K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-06-23 00:43:57 (76.0 MB/s) - ‘losses.py.3’ saved [5169/5169]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/wangz10/contrastive_loss/master/losses.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MEEKBji523SY",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aksavadogo/anaconda3/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tqdm.notebook import tqdm\n",
    "from wandb.keras import WandbCallback\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import losses\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(666)\n",
    "np.random.seed(666)\n",
    "\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-23 05:50:55.951933: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-23 05:50:56.153667: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BaNA_SqCBpjt"
   },
   "source": [
    "## Pets dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir='data/train/'\n",
    "batch_size=32\n",
    "img_height=510\n",
    "img_width=503"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hyUM4mdE4CfU",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6984 files belonging to 2 classes.\n",
      "Using 6286 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    labels='inferred',\n",
    "    label_mode = 'categorical',\n",
    "    class_names = ['benign', 'malicious'],\n",
    "    color_mode = 'rgb',\n",
    "    batch_size = batch_size,\n",
    "    image_size = (img_height, img_width),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.1,\n",
    "    subset=\"training\",\n",
    "    interpolation='lanczos3',\n",
    ")                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "colab_type": "code",
    "id": "wYFDSfSS4GR2",
    "outputId": "1b4a1c79-bc46-455f-d7a4-914d5f20d588",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reference: https://keras.io/guides/transfer_learning/\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, (image, label) in enumerate(train_ds.take(9)):\n",
    "    image = np.array(image)  # Convert image to NumPy array\n",
    "    image = np.squeeze(image, axis=0)  # Remove batch size dimension\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(int(label))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "js6NcflSBrpE"
   },
   "source": [
    "## Data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8z4np9oZ4cs1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#IMG_SHAPE = 128\n",
    "#BS = 64\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "@tf.function\n",
    "def preprocess_image(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, (img_height, img_width))\n",
    "\n",
    "    return (image, label)\n",
    "\n",
    "train_ds = (\n",
    "    train_ds\n",
    "    .map(preprocess_image, num_parallel_calls=AUTO)\n",
    "    .shuffle(100)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTO)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ECAnGraOBvD9"
   },
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "plwzuhfa5PVA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reference: https://github.com/wangz10/contrastive_loss/blob/master/model.py\n",
    "class UnitNormLayer(tf.keras.layers.Layer):\n",
    "    '''Normalize vectors (euclidean norm) in batch to unit hypersphere.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(UnitNormLayer, self).__init__()\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        norm = tf.norm(input_tensor, axis=1)\n",
    "        return input_tensor / tf.reshape(norm, [-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hlFFQwIS5SDB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encoder Network\n",
    "def encoder_net():\n",
    "\tinputs = Input((img_height, img_width, 3))\n",
    "\tnormalization_layer = UnitNormLayer()\n",
    "\n",
    "\tencoder = tf.keras.applications.ResNet50(weights=None, include_top=False)\n",
    "\tencoder.trainable = True\n",
    "\n",
    "\tembeddings = encoder(inputs, training=True)\n",
    "\tembeddings = GlobalAveragePooling2D()(embeddings)\n",
    "\tnorm_embeddings = normalization_layer(embeddings)\n",
    "\n",
    "\tencoder_network = Model(inputs, norm_embeddings)\n",
    "\n",
    "\treturn encoder_network\n",
    "\n",
    "# Projector Network\n",
    "def projector_net():\n",
    "\tprojector = tf.keras.models.Sequential([\n",
    "\t\tDense(128, activation=\"relu\"),\n",
    "\t\tUnitNormLayer()\n",
    "\t])\n",
    "\n",
    "\treturn projector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i5pxYaM_ByeO"
   },
   "source": [
    "## Running forward passes on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "W5QgLzDK6d2H",
    "outputId": "d9e01002-f855-4506-fd16-be4c53401608",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-23 05:51:29.527151: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [6286]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-23 05:51:29.528196: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [6286]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-23 05:51:30.517274: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 98507520 exceeds 10% of free system memory.\n",
      "2023-06-23 05:51:30.546215: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 98507520 exceeds 10% of free system memory.\n",
      "2023-06-23 05:51:30.632407: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 98507520 exceeds 10% of free system memory.\n",
      "2023-06-23 05:51:30.670975: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 98507520 exceeds 10% of free system memory.\n",
      "2023-06-23 05:51:30.763558: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 98507520 exceeds 10% of free system memory.\n",
      "2023-06-23 05:51:39.859144: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 34 of 100\n",
      "2023-06-23 05:51:49.798932: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 67 of 100\n",
      "2023-06-23 05:51:59.684341: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 98 of 100\n",
      "2023-06-23 05:52:00.322536: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n"
     ]
    }
   ],
   "source": [
    "encoder_r = encoder_net()\n",
    "projector_z = projector_net()\n",
    "\n",
    "images, _ = next(iter(train_ds))\n",
    "r = encoder_r(images[0], 0)\n",
    "z = projector_z(r)\n",
    "\n",
    "print(tf.shape(r))\n",
    "print(tf.shape(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3lRji6rrB141"
   },
   "source": [
    "## Training the encoder and the projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f7e7r0xW8zlM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pEtX8gQY7OIE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder_r = encoder_net()\n",
    "projector_z = projector_net()\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "\twith tf.GradientTape() as tape:\n",
    "\t\tr = encoder_r(images, training=True)\n",
    "\t\tz = projector_z(r, training=True)\n",
    "\t\tloss = losses.max_margin_contrastive_loss(z, labels, metric='cosine')\n",
    "\n",
    "\tgradients = tape.gradient(loss, \n",
    "\t\tencoder_r.trainable_variables + projector_z.trainable_variables)\n",
    "\toptimizer.apply_gradients(zip(gradients, \n",
    "\t\tencoder_r.trainable_variables + projector_z.trainable_variables))\n",
    "\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jiV_oi3D8mbw",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:j7sl2ipm) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mild-sunset-1</strong> at: <a href='https://wandb.ai/burkinabe/scl/runs/j7sl2ipm' target=\"_blank\">https://wandb.ai/burkinabe/scl/runs/j7sl2ipm</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230622_224115-j7sl2ipm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:j7sl2ipm). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b83dbb316b34d659d2e353a1eb9d6a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016670240650031094, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aksavadogo/codespace/memoire/Supervised-Contrastive-Learning-in-TensorFlow-2/Pets/wandb/run-20230622_224147-hnamyd2j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/burkinabe/scl/runs/hnamyd2j' target=\"_blank\">charmed-frog-2</a></strong> to <a href='https://wandb.ai/burkinabe/scl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/burkinabe/scl' target=\"_blank\">https://wandb.ai/burkinabe/scl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/burkinabe/scl/runs/hnamyd2j' target=\"_blank\">https://wandb.ai/burkinabe/scl/runs/hnamyd2j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55cd5ec921cb4ff0ac86f43d7c97b916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n",
      "Warning: unknown JFIF revision number 0.00\n",
      "Corrupt JPEG data: 396 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 252 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 128 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 239 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 228 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 0.275\n"
     ]
    }
   ],
   "source": [
    "wandb.init(project=\"scl\", entity=\"burkinabe\")\n",
    "EPOCHS = 60\n",
    "LOG_EVERY = 10\n",
    "train_loss_results = []\n",
    "\n",
    "start = time.time()\n",
    "for epoch in tqdm(range(EPOCHS)):\t\n",
    "\tepoch_loss_avg = tf.keras.metrics.Mean()\n",
    "\t\n",
    "\tfor (images, labels) in train_ds:\n",
    "\t\tloss = train_step(images, labels)\n",
    "\t\tepoch_loss_avg.update_state(loss) \n",
    "\n",
    "\ttrain_loss_results.append(epoch_loss_avg.result())\n",
    "\twandb.log({\"supervised_contrastive_loss\": epoch_loss_avg.result()})\n",
    "\n",
    "\tif epoch % LOG_EVERY == 0:\n",
    "\t\tprint(\"Epoch: {} Loss: {:.3f}\".format(epoch, epoch_loss_avg.result()))\n",
    "\n",
    "end = time.time()\n",
    "wandb.log({\"training_time\": end - start})\n",
    "\n",
    "with plt.xkcd():\n",
    "    plt.plot(train_loss_results)\n",
    "    plt.title(\"Supervised Contrastive Loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2papzigtWHdi"
   },
   "source": [
    "## Supervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R9oc1TodWA4T"
   },
   "outputs": [],
   "source": [
    "validation_ds = (\n",
    "    validation_ds\n",
    "    .map(preprocess_image, num_parallel_calls=AUTO)\n",
    "    .shuffle(100)\n",
    "    .batch(BS)\n",
    "    .prefetch(AUTO)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rz-4RowrWE4g"
   },
   "outputs": [],
   "source": [
    "def supervised_model():\n",
    "\tinputs = Input((IMG_SHAPE, IMG_SHAPE, 3))\n",
    "\tencoder_r.trainable = False\n",
    "\n",
    "\tr = encoder_r(inputs, training=False)\n",
    "\toutputs = Dense(1)(r)\n",
    "\n",
    "\tsupervised_model = Model(inputs, outputs)\n",
    "\n",
    "\treturn supervised_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "Wqn9xto-WFjX",
    "outputId": "f2354f5e-103d-4aa0-e003-d1017943e84f"
   },
   "outputs": [],
   "source": [
    "supervised_classifier = supervised_model()\n",
    "\n",
    "supervised_classifier.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "\tloss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "\tmetrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "\n",
    "wandb.init(project=\"scl\", entity=\"authors\")\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2,\n",
    "\trestore_best_weights=True, verbose=2)\n",
    "\n",
    "supervised_classifier.fit(train_ds,\n",
    "\tvalidation_data=validation_ds,\n",
    "\tepochs=50,\n",
    "\tcallbacks=[WandbCallback(), es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "PrSKZVYNiGQr",
    "outputId": "6432d1f9-5c7b-4529-b186-0ce34b13bb1c"
   },
   "outputs": [],
   "source": [
    "# Lowering the learning rate\n",
    "supervised_classifier = supervised_model()\n",
    "\n",
    "supervised_classifier.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4),\n",
    "\tloss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "\tmetrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "\n",
    "wandb.init(project=\"scl\", entity=\"authors\", id=\"low-lr\")\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2,\n",
    "\trestore_best_weights=True, verbose=2)\n",
    "\n",
    "supervised_classifier.fit(train_ds,\n",
    "\tvalidation_data=validation_ds,\n",
    "\tepochs=50,\n",
    "\tcallbacks=[WandbCallback(), es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "orkuHb3aldCc"
   },
   "source": [
    "With more training for the encoder and the projector, we would have got better results. We did not use any augmentation policy for either of the trainings above, so including that would have also helped us enhance the performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ywCd0fkVWRxI"
   },
   "source": [
    "## Serialize the model weights to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Mckar8uNWLHs",
    "outputId": "f9c4d048-9b55-447e-b7c7-6291f3e6d00c"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "PROJECT_ID = \"fast-ai-exploration\" \n",
    "!gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "p6lSuPfbWNLR",
    "outputId": "1973be06-da24-4e97-c11a-de176ae9f969"
   },
   "outputs": [],
   "source": [
    "!gsutil mb gs://supervised-contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "okEXqq74WP0B",
    "outputId": "ffbf8238-b4b0-4e07-a88b-ee98791eb1c4"
   },
   "outputs": [],
   "source": [
    "time_now = time.time()\n",
    "encoder_r.save_weights(\"encoder_r_\" + str(time_now) + \".h5\")\n",
    "projector_z.save_weights(\"projector_z\" + str(time_now) + \".h5\")\n",
    "\n",
    "!gsutil -m cp -r *.h5 gs://supervised-contrastive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "scratchpad",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
